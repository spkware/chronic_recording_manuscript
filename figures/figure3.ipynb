{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9fa4ca-6d01-4462-ad4e-4f7b6283f45f",
   "metadata": {},
   "source": [
    "# Motion across sessions - comparisson with the cemented dataset\n",
    "\n",
    "These will go in sup, perhaps all combined would be nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062c0fa-0c32-44ae-8985-5b45ed295749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labdata.schema import *\n",
    "import pylab as plt\n",
    "%matplotlib widget\n",
    "from labdata import chronic_paper as paper\n",
    "plt.matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "plt.matplotlib.rcParams['ps.fonttype'] = 42\n",
    "savepath = Path('../../figures/figure3')\n",
    "savepath.mkdir(parents = True,exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0beaf-b22b-4210-b54e-fa99bb1546d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "key = dict(subject_name=\"_AL032\",shank_num=0)\n",
    "import pylab as plt\n",
    "plt.figure()\n",
    "paper.ConcatenatedSpikes().plot_raster(key, corrected=False, overlay_dredge=True,cmap = 'gray')\n",
    "plt.axis('tight')\n",
    "# plt.ylim(4200, 5200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b11848-51b7-4fe2-bcca-1dcca895d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_days = (paper.ConcatenatedSpikes.IncludedSessions()*Session() & 'subject_name = \"_AL031\"'& 'shank_num = 0').fetch('session_datetime')\n",
    "intervals_days = (intervals_days.astype(np.datetime64) - np.datetime64(intervals_days[0]))\n",
    "intervals_days_cemented = intervals_days.astype('timedelta64[D]') # these are the intervals for which we have _AL036 data\n",
    "\n",
    "\n",
    "# selected JC131 sessions\n",
    "intervals_days = (paper.ConcatenatedSpikes.IncludedSessions()*Session() & 'subject_name = \"JC131\"'& 'shank_num = 0').fetch('session_datetime')\n",
    "intervals_days = (intervals_days.astype(np.datetime64) - np.datetime64(intervals_days[0])).astype('timedelta64[D]')\n",
    "arg_sessions = []\n",
    "for i in intervals_days_cemented:\n",
    "    arg_sessions.append(np.where(intervals_days<=i)[0][-1])\n",
    "arg_sessions\n",
    "intervals_days,intervals_days_cemented,arg_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb38139-90b2-4d52-9773-0c7a55363236",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_AL036 = (paper.ConcatenatedSpikes*paper.ConcatenatedSpikes.DredgeResults & 'subject_name = \"_AL036\"' & 'shank_num = 0').fetch1()\n",
    "intervals_days = (paper.ConcatenatedSpikes.IncludedSessions()*Session() & 'subject_name = \"_AL036\"'& 'shank_num = 0').fetch('session_datetime')\n",
    "intervals_days = (intervals_days.astype(np.datetime64) - np.datetime64(intervals_days[0]))\n",
    "intervals_days_cemented = intervals_days.astype('timedelta64[D]') # these are the intervals for which we have _AL036 data\n",
    "\n",
    "data_AL036['spike_times_s'] = data_AL036['spike_times_s'].astype(np.float32)\n",
    "displ = data_AL036['displacement']\n",
    "sp= data_AL036['spike_times_s']\n",
    "\n",
    "from spks.viz import plot_drift_raster\n",
    "\n",
    "plt.figure(figsize = [7,3])\n",
    "plot_drift_raster(sp,data_AL036['spike_depths_um'],data_AL036['spike_amps'],cmap = 'gray_r',clim = [0,300])\n",
    "\n",
    "offsets = np.hstack([data_AL036['session_breaks'],np.max(sp)])\n",
    "\n",
    "plt.vlines(offsets,3500,4500,'k',lw = 0.5)\n",
    "plt.ylim([3500,4500])\n",
    "plt.plot(displ+np.mean([3500,4500]),'r')\n",
    "plt.xticks(offsets - np.mean(np.diff(offsets))/2,[a for a in intervals_days_cemented.astype(int)],rotation = 0,fontsize = 8);\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.ylabel(\"Probe location (um)\")\n",
    "plt.xlabel(\"Days from first recording\");\n",
    "plt.title('AL036 cortex (shank 0)')\n",
    "plt.savefig(savepath/f'AL036_shank0_drift.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc56a6-4be2-4d86-a608-14fa87a57f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "shank = 3\n",
    "data_AL032 = (paper.ConcatenatedSpikes*paper.ConcatenatedSpikes.DredgeResults & 'subject_name = \"_AL032\"' & f'shank_num = {shank}').fetch1()\n",
    "intervals_days = (paper.ConcatenatedSpikes.IncludedSessions()*Session() & 'subject_name = \"_AL032\"'& f'shank_num = {shank}').fetch('session_datetime')\n",
    "intervals_days = (intervals_days.astype(np.datetime64) - np.datetime64(intervals_days[0]))\n",
    "intervals_days_cemented = intervals_days.astype('timedelta64[D]') # these are the intervals for which we have _AL036 data\n",
    "\n",
    "data_AL032['spike_times_s'] = data_AL032['spike_times_s'].astype(np.float32)\n",
    "displ = data_AL032['displacement']\n",
    "sp= data_AL032['spike_times_s']\n",
    "\n",
    "from spks.viz import plot_drift_raster\n",
    "\n",
    "plt.figure(figsize = [7,3])\n",
    "plot_drift_raster(sp,data_AL032['spike_depths_um'],data_AL032['spike_amps'],cmap = 'gray_r',clim = [0,300])\n",
    "\n",
    "plt.vlines(offsets,2700,3700,'k',lw = 0.5)\n",
    "plt.ylim([2700,3700])\n",
    "plt.plot(displ+np.mean([2700,3700]),'r')\n",
    "offsets = np.hstack([data_AL032['session_breaks'],np.max(sp)])\n",
    "plt.xticks(offsets - np.mean(np.diff(offsets))/2,[a for a in intervals_days_cemented.astype(int)],rotation = 0,fontsize = 8);\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.ylabel(\"Probe location (um)\")\n",
    "plt.xlabel(\"Days from first recording\");\n",
    "plt.title(f'AL032 cortex (shank {shank})')\n",
    "plt.savefig(savepath/f'AL032_shank{shank}_drift.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee1cdd-fb7e-4de5-95ed-4e0d1eda3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_days = (paper.ConcatenatedSpikes.IncludedSessions()*Session() & 'subject_name = \"JC131\"'& 'shank_num = 0').fetch('session_datetime')\n",
    "intervals_days = (intervals_days.astype(np.datetime64) - np.datetime64(intervals_days[0])).astype('timedelta64[D]')\n",
    "\n",
    "idx_JC131 = [0,1,8,30,34,46,59,68,76,77,78,84,87]\n",
    "\n",
    "data_JC131 = (paper.ConcatenatedSpikes*paper.ConcatenatedSpikes.DredgeResults & 'subject_name = \"JC131\"' & 'shank_num = 0').fetch1()\n",
    "\n",
    "data_JC131['spike_times_s'] = data_JC131['spike_times_s'].astype(np.float32)\n",
    "sessiontimes = np.vstack([np.hstack([4,data_JC131['session_breaks']]),\n",
    "                          np.hstack([data_JC131['session_breaks'],np.max(data_JC131['spike_times_s'])])]).T[idx_JC131]\n",
    "t = data_JC131['time_bin_centers_s']\n",
    "displ = data_JC131['displacement'][np.hstack([np.where((t>a) & (t<=b))[0] for a,b in sessiontimes])]\n",
    "sp= data_JC131['spike_times_s']\n",
    "idx = [np.where((sp>a) & (sp<=b))[0] for a,b in sessiontimes]\n",
    "\n",
    "nsp = []\n",
    "offsets = []\n",
    "offset = 0\n",
    "for i in idx:\n",
    "    nsp.append(sp[i]-sp[i][0]+offset)\n",
    "    offset = nsp[-1][-1]\n",
    "    offsets.append(offset)\n",
    "idx = np.hstack(idx)\n",
    "from spks.viz import plot_drift_raster\n",
    "\n",
    "plt.figure(figsize = [7,3])\n",
    "plot_drift_raster(np.hstack(nsp),data_JC131['spike_depths_um'][idx],data_JC131['spike_amps'][idx],cmap = 'gray_r',clim = [0,300])\n",
    "\n",
    "plt.vlines(offsets,4200,5200,'k',lw = 0.5)\n",
    "plt.ylim([4200,5200])\n",
    "plt.plot(displ+np.mean([4200,5200]),'r')\n",
    "plt.xticks(offsets - np.mean(np.diff(offsets))/2,[a for a in intervals_days[idx_JC131].astype(int)],rotation = 0,fontsize = 8);\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.ylabel(\"Probe location (um)\")\n",
    "plt.xlabel(\"Days from first recording\");\n",
    "plt.title('JC131 cortex (shank 0)')\n",
    "plt.savefig(savepath/f'JC131_shank0_drift.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8163beaf-ffe3-4d7c-af96-d83db9e3ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_days = (paper.ConcatenatedSpikes.IncludedSessions()*Session() & 'subject_name = \"JC131\"'& 'shank_num = 2').fetch('session_datetime')\n",
    "intervals_days = (intervals_days.astype(np.datetime64) - np.datetime64(intervals_days[0])).astype('timedelta64[D]')\n",
    "\n",
    "idx_JC131 = [0,1,8,30,34,46,59,68,76,77,78,84,87]\n",
    "\n",
    "data_JC131 = (paper.ConcatenatedSpikes*paper.ConcatenatedSpikes.DredgeResults & 'subject_name = \"JC131\"' & 'shank_num = 2').fetch1()\n",
    "\n",
    "data_JC131['spike_times_s'] = data_JC131['spike_times_s'].astype(np.float32)\n",
    "sessiontimes = np.vstack([np.hstack([0,data_JC131['session_breaks']]),\n",
    "                          np.hstack([data_JC131['session_breaks'],np.max(data_JC131['spike_times_s'])])]).T[idx_JC131]\n",
    "t = data_JC131['time_bin_centers_s']\n",
    "displ = data_JC131['displacement'][2][np.hstack([np.where((t>a) & (t<=b))[0] for a,b in sessiontimes])]\n",
    "sp= data_JC131['spike_times_s']\n",
    "idx = [np.where((sp>a) & (sp<=b))[0] for a,b in sessiontimes]\n",
    "\n",
    "nsp = []\n",
    "offsets = []\n",
    "offset = 0\n",
    "for i in idx:\n",
    "    nsp.append(sp[i]-sp[i][0]+offset)\n",
    "    offset = nsp[-1][-1]\n",
    "    offsets.append(offset)\n",
    "idx = np.hstack(idx)\n",
    "from spks.viz import plot_drift_raster\n",
    "\n",
    "plt.figure(figsize = [7,3])\n",
    "plot_drift_raster(np.hstack(nsp),data_JC131['spike_depths_um'][idx],data_JC131['spike_amps'][idx],cmap = 'gray_r',clim = [0,300])\n",
    "\n",
    "plt.vlines(offsets,1300,2300,'k',lw = 0.5)\n",
    "plt.ylim([1300,2300])\n",
    "plt.plot(displ+np.mean([1300,2300]),'r')\n",
    "plt.xticks(offsets - np.mean(np.diff(offsets))/2,[a for a in intervals_days[idx_JC131].astype(int)],rotation = 0,fontsize = 8);\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.ylabel(\"Probe location (um)\")\n",
    "plt.xlabel(\"Days from first recording\");\n",
    "plt.title('JC131 thalamus (shank 2)')\n",
    "plt.savefig(savepath/f'JC131_shank2_drift.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0d45f-bd64-4490-9534-39d4a09ec969",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_days = (paper.ConcatenatedSpikes.IncludedSessions()*Session() & 'subject_name = \"MM012\"'&\n",
    "                  'probe_num = 2' & 'shank_num = 0').fetch('session_datetime')\n",
    "intervals_days = (intervals_days.astype(np.datetime64) - np.datetime64(intervals_days[0])).astype('timedelta64[D]')\n",
    "idx_MM012 = [0,1,6,18, 19, 20,24,32, 33, 40, 41 ,44,48]\n",
    "data_MM012 = (paper.ConcatenatedSpikes*paper.ConcatenatedSpikes.DredgeResults & 'subject_name = \"MM012\"' \n",
    "              & 'probe_num = 2' \n",
    "              & 'shank_num = 0').fetch1()\n",
    "\n",
    "\n",
    "data_MM012['spike_times_s'] = data_MM012['spike_times_s'].astype(np.float32)\n",
    "sessiontimes = np.vstack([np.hstack([4,data_MM012['session_breaks']]),\n",
    "                          np.hstack([data_MM012['session_breaks'],np.max(data_MM012['spike_times_s'])])]).T[idx_MM012]\n",
    "t = data_MM012['time_bin_centers_s']\n",
    "displ = data_MM012['displacement'][2][np.hstack([np.where((t>a) & (t<=b))[0] for a,b in sessiontimes])]\n",
    "sp= data_MM012['spike_times_s']\n",
    "idx = [np.where((sp>a) & (sp<=b))[0] for a,b in sessiontimes]\n",
    "\n",
    "nsp = []\n",
    "offsets = []\n",
    "offset = 0\n",
    "for i in idx:\n",
    "    nsp.append(sp[i]-sp[i][0]+offset)\n",
    "    offset = nsp[-1][-1]\n",
    "    offsets.append(offset)\n",
    "idx = np.hstack(idx)\n",
    "from spks.viz import plot_drift_raster\n",
    "\n",
    "plt.figure(figsize = [7,3])\n",
    "plot_drift_raster(np.hstack(nsp),data_MM012['spike_depths_um'][idx],data_MM012['spike_amps'][idx],cmap = 'gray_r',clim = [0,70])\n",
    "\n",
    "plt.vlines(offsets,2800,3800,'k',lw = 0.5)\n",
    "plt.ylim([2800,3800])\n",
    "plt.plot(displ+np.mean([2800,3800]),'r')\n",
    "plt.xticks(offsets - np.mean(np.diff(offsets))/2,[a for a in intervals_days[idx_MM012].astype(int)],rotation = 0,fontsize = 8);\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.ylabel(\"Probe location (um)\")\n",
    "plt.xlabel(\"Days from first recording\");\n",
    "plt.title('MM012 cortex (NP1)')\n",
    "plt.savefig(savepath/f'MM012_shank2_drift.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2588ff1-73ea-4177-adc6-4f2a2a9ae7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intervals_days = (paper.ConcatenatedSpikes.IncludedSessions()*Session() & 'subject_name = \"MM012\"'&\n",
    "                  'probe_num = 1' & 'shank_num = 0').fetch('session_datetime')\n",
    "intervals_days = (intervals_days.astype(np.datetime64) - np.datetime64(intervals_days[0])).astype('timedelta64[D]')\n",
    "idx_MM012 = [0,1,6,18, 19, 20,24,32, 33, 40, 41 ,44,48]\n",
    "data_MM012 = (paper.ConcatenatedSpikes*paper.ConcatenatedSpikes.DredgeResults & 'subject_name = \"MM012\"' \n",
    "              & 'probe_num = 1' \n",
    "              & 'shank_num = 0').fetch1()\n",
    "\n",
    "\n",
    "data_MM012['spike_times_s'] = data_MM012['spike_times_s'].astype(np.float32)\n",
    "sessiontimes = np.vstack([np.hstack([4,data_MM012['session_breaks']]),\n",
    "                          np.hstack([data_MM012['session_breaks'],np.max(data_MM012['spike_times_s'])])]).T[idx_MM012]\n",
    "t = data_MM012['time_bin_centers_s']\n",
    "displ = data_MM012['displacement'][-2][np.hstack([np.where((t>a) & (t<=b))[0] for a,b in sessiontimes])]\n",
    "sp= data_MM012['spike_times_s']\n",
    "idx = [np.where((sp>a) & (sp<=b))[0] for a,b in sessiontimes]\n",
    "\n",
    "nsp = []\n",
    "offsets = []\n",
    "offset = 0\n",
    "for i in idx:\n",
    "    nsp.append(sp[i]-sp[i][0]+offset)\n",
    "    offset = nsp[-1][-1]\n",
    "    offsets.append(offset)\n",
    "idx = np.hstack(idx)\n",
    "from spks.viz import plot_drift_raster\n",
    "\n",
    "plt.figure(figsize = [7,3])\n",
    "plot_drift_raster(np.hstack(nsp),data_MM012['spike_depths_um'][idx],data_MM012['spike_amps'][idx],cmap = 'gray_r',clim = [0,70])\n",
    "\n",
    "plt.vlines(offsets,2600,3600,'k',lw = 0.5)\n",
    "plt.ylim([2600,3600])\n",
    "plt.plot(displ+np.mean([2600,3600]),'r')\n",
    "plt.xticks(offsets - np.mean(np.diff(offsets))/2,[a for a in intervals_days[idx_MM012].astype(int)],rotation = 0,fontsize = 8);\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.ylabel(\"Probe location (um)\")\n",
    "plt.xlabel(\"Days from first recording\");\n",
    "plt.title('MM012 motor cortex (NP1)')\n",
    "plt.savefig(savepath/f'MM012_shank0_drift.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44712030-b923-47df-a9d0-0fcf143f2ecf",
   "metadata": {},
   "source": [
    "# Example of session to session motion estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959aaba-9fcd-4d35-9ad3-8e4cc4224af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labdata.schema import *\n",
    "import pylab as plt\n",
    "%matplotlib widget\n",
    "from labdata import chronic_paper as paper\n",
    "plt.matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "plt.matplotlib.rcParams['ps.fonttype'] = 42\n",
    "savepath = Path('../../figures/figure3')\n",
    "savepath.mkdir(parents = True,exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f50dd-0fe7-44d6-9aec-ef12d024ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015c23c-1a52-4ae1-82f5-bd8e4b47dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_days = (paper.ConcatenatedSpikes.IncludedSessions()*Session() & 'subject_name = \"JC131\"'& 'shank_num = 2').fetch('session_datetime')\n",
    "intervals_days = (intervals_days.astype(np.datetime64) - np.datetime64(intervals_days[0])).astype('timedelta64[D]')\n",
    "\n",
    "idx_JC131 = [1,9,18,24,28,35,41,51,53,59,64,65,69,76,79,80,90,97,99,103,106,111,114,119,123,128]\n",
    "\n",
    "#data_JC131 = (paper.ConcatenatedSpikes*paper.ConcatenatedSpikes.DredgeResults & 'subject_name = \"JC131\"' & 'shank_num = 2').fetch1()\n",
    "\n",
    "data_JC131['spike_times_s'] = data_JC131['spike_times_s'].astype(np.float32)\n",
    "sessiontimes = np.vstack([np.hstack([0,data_JC131['session_breaks']]),\n",
    "                          np.hstack([data_JC131['session_breaks'],np.max(data_JC131['spike_times_s'])])]).T[idx_JC131]\n",
    "t = data_JC131['time_bin_centers_s']\n",
    "displ = data_JC131['displacement'][0][np.hstack([np.where((t>a) & (t<=b))[0] for a,b in sessiontimes])]\n",
    "sp= data_JC131['spike_times_s']\n",
    "idx = [np.where((sp>a) & (sp<=b))[0] for a,b in sessiontimes]\n",
    "\n",
    "nsp = []\n",
    "offsets = []\n",
    "offset = 0\n",
    "for i in idx:\n",
    "    nsp.append(sp[i]-sp[i][0]+offset)\n",
    "    offset = nsp[-1][-1]\n",
    "    offsets.append(offset)\n",
    "idx = np.hstack(idx)\n",
    "from spks.viz import plot_drift_raster\n",
    "\n",
    "plt.figure(figsize = [8,1.5])\n",
    "plot_drift_raster(np.hstack(nsp),\n",
    "                  data_JC131['spike_depths_um'][idx],\n",
    "                  data_JC131['spike_amps'][idx],\n",
    "                  cmap = 'gray_r',clim = [0,300],\n",
    "                  markersize = 0.001,\n",
    "                  n_spikes_to_plot = 150000)\n",
    "\n",
    "plt.vlines(offsets,1300,2300,'k',lw = 0.5)\n",
    "plt.ylim([1400,2150])\n",
    "plt.plot(displ+np.mean([1300,2300]),'r')\n",
    "plt.xticks(offsets - np.mean(np.diff(offsets))/2,[a for a in intervals_days[idx_JC131].astype(int)],rotation = 0,fontsize = 8);\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.ylabel(\"Probe location (um)\")\n",
    "plt.xlabel(\"Days from first recording\");\n",
    "plt.title('JC131 thalamus (shank 2)')\n",
    "plt.savefig(savepath/f'longitudinal_JC131_shank2_motion.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72057e7-ea58-46ad-909f-40ca3cacd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.DredgeSpikeDetection() & 'subject_name = \"MM008\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470aa93-7c47-4b95-b680-b5697c05bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['JC131', 'MM012', 'MM013', '_AL031', '_AL032','_AL036']\n",
    "subjects = ['JC131', 'MM018','MM013','_AL031', '_AL032','_AL036']\n",
    "def compute_intersession_drift(displacement, session_breaks):\n",
    "    lims = np.concatenate([np.array([0]), session_breaks])\n",
    "    avg_pos = []\n",
    "    for start, end in zip(lims[:-1], lims[1:]):\n",
    "        avg_pos.append(np.mean(displacement[start:end])) # mean position per session\n",
    "    diffs = np.diff(avg_pos)\n",
    "    return avg_pos, diffs\n",
    "    \n",
    "# subjects = np.unique(paper.ConcatenatedSpikes.fetch('subject_name'))\n",
    "violinres = []\n",
    "caption = []\n",
    "for subject in subjects:\n",
    "    res = pd.DataFrame(((paper.ConcatenatedSpikes.DredgeResults() * paper.ConcatenatedSpikes().proj('session_breaks') \n",
    "                         & f\"subject_name = '{subject}'\")).fetch())\n",
    "    for i,r in res.iterrows():\n",
    "        displacement = r['displacement']\n",
    "        if len(displacement.shape)==1:\n",
    "            displacement = [displacement]\n",
    "        avg_pos = []\n",
    "        diffs = []\n",
    "        if 'MM018' in subject and r.shank_num and i>=1:\n",
    "            continue\n",
    "        for i,d in enumerate(displacement):\n",
    "            a,d = compute_intersession_drift(d,r['session_breaks'])\n",
    "\n",
    "            if not np.mean(np.abs(a)) < 2:\n",
    "                avg_pos.append(a)\n",
    "                diffs.append(a)\n",
    "        if len(diffs):\n",
    "            \n",
    "            violinres.append(dict(subject_name = subject, \n",
    "                                  probe_num = r.probe_num,\n",
    "                                  shank_num = r.shank_num,\n",
    "                                  pos_average = avg_pos,\n",
    "                                  dates = (paper.ConcatenatedSpikes.IncludedSessions()*Session() \n",
    "                                           & f'subject_name = \"{subject}\"').fetch('session_datetime'),\n",
    "                                 pos_difference = diffs))\n",
    "            \n",
    "            caption.append(subject + f' probe {r.probe_num} shank {r.shank_num}')\n",
    "violinres = pd.DataFrame(violinres)\n",
    "\n",
    "# res['spatial_bin_centers_um'].iloc[0]\n",
    "# violinres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b95f5-b18c-4541-bd8f-184d49546d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [8,3])\n",
    "fig.add_axes([0.2,0.4,0.7,0.5])\n",
    "dd = violinres.pos_difference.values\n",
    "values = [np.abs(np.stack(d).flatten()) for d in dd]\n",
    "ii = [np.random.uniform(0,0.1,size = d.shape)+i for i,d in enumerate(values)]\n",
    "\n",
    "viol = plt.violinplot(values,showmedians=True);\n",
    "plt.xticks(1+np.arange(len(violinres)),[f'{r.subject_name} shank {r.shank_num}' for i,r in violinres.iterrows()],rotation = 90,fontsize = 6);\n",
    "for i,b in enumerate(viol['bodies']):\n",
    "    c = 'k'\n",
    "    b.set_edgecolor(c)\n",
    "    if 'AL' in caption[i]:\n",
    "        b.set_facecolor('gray')\n",
    "    else:\n",
    "        b.set_facecolor('lightgray')\n",
    "    b.set_alpha(1)\n",
    "viol['cmedians'].set_color('k')\n",
    "viol['cbars'].set_color('k')\n",
    "viol['cmins'].set_color('k')\n",
    "viol['cmaxes'].set_color('k')\n",
    "plt.xticks(1+np.arange(len(violinres)),caption)\n",
    "plt.gca().spines[['top','right']].set_visible(False)\n",
    "plt.ylim([0,200])\n",
    "plt.ylabel('delta session motion', fontsize = 12)\n",
    "plt.savefig(savepath/f'all_probe_motion_violins_MM018.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6b272-6a53-4ae3-85b8-7136e24cf0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.DataFrame(paper.ConcatenatedSpikes.DredgeResults() & key).fetch())\n",
    "# for s in subjects:\n",
    "# (paper.ConcatenatedSpikes() & key)\n",
    "\n",
    "\n",
    "# subject_sessions = (paper.ConcatenatedSpikes.IncludedSessions()*Session()).fetch('session_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53b672-016d-4011-87b2-cf32985173e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#intersession_positions, intersession_drifts = [(compute_intersession_drift(m, lims)) for m in shank_motion_estimates]\n",
    "# intersession_drifts = [compute_intersession_drift(m, lims) for m in shank_motion_estimates]\n",
    "\n",
    "np.nanmin(anova_table['PR(>F)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc26e41-01a9-448d-bd15-c8b9526ee0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats for violin plot\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    " \n",
    "dat = violinres[['subject_name','shank_num','pos_difference']].copy()\n",
    "dat = dat.explode('pos_difference').explode('pos_difference').reindex()\n",
    "dat['pos_difference'] = dat['pos_difference'].astype(float)\n",
    "#model = ols('pos_difference ~ C(subject_name) + C(shank_num) + C(subject_name):C(shank_num)', data=dat).fit()\n",
    "model = ols('pos_difference ~ C(subject_name)*C(shank_num)', data=dat).fit()\n",
    "#print(model.summary())\n",
    "anova_table = sm.stats.anova_lm(model, typ=3)\n",
    "print(anova_table)\n",
    "tukey_animal = pairwise_tukeyhsd(endog=dat['pos_difference'], groups=dat['subject_name'], alpha=0.05)\n",
    "print(tukey_animal)\n",
    "tukey_shank = pairwise_tukeyhsd(endog=dat['pos_difference'], groups=dat['shank_num'].values, alpha=0.05)\n",
    "print(tukey_shank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2ca93-4601-453a-90d3-b7d4a745e4fd",
   "metadata": {},
   "source": [
    "### Comparisson of unit yield with cemented probes \n",
    "\n",
    "Chosen only sessions with probes in V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398fabc9-5b82-45ac-a5c4-4253f5b20224",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEPATH = Path('../../figures/figure3')\n",
    "SUBJECTS = ['_AL031','_AL032','_AL036','MM013','MM018','JC131']\n",
    "PROBE_NUMS = [0,0,0,2,2,0]\n",
    "\n",
    "cemented_subjects = SUBJECTS[:3]\n",
    "chronic_holder_subjects = SUBJECTS[3:]\n",
    "\n",
    "subjects = '(' + ','.join([f'\"{s}\"' for s in SUBJECTS]) + ')'\n",
    "dat = pd.DataFrame()\n",
    "for s,p in zip(SUBJECTS,PROBE_NUMS):\n",
    "    unit_counts = Session() * UnitCount() & dict(subject_name=s,\n",
    "                                                 probe_num=p,\n",
    "                                                 parameter_set_num=5,\n",
    "                                                 unit_criteria_id=1)\n",
    "    subject_data = unit_counts.proj('session_datetime','all','sua','mua').fetch(format='frame')\n",
    "    dat = pd.concat([dat,subject_data])\n",
    "dat = dat.reset_index()\n",
    "\n",
    "cemented_sessions = dat[dat.subject_name.isin(cemented_subjects)]\n",
    "chronic_holder_sessions = dat[dat.subject_name.isin(chronic_holder_subjects)]\n",
    "\n",
    "# randomly subsample our chronic holder mice so that they're equal in number for randomly selecting sessions\n",
    "min_num_sessions = chronic_holder_sessions.subject_name.value_counts().min()\n",
    "subsample_group = lambda group, n_per_subject:  group.sample(n=n_per_subject, replace=True) \n",
    "chronic_holder_sessions = chronic_holder_sessions.groupby('subject_name', group_keys=False).apply(subsample_group, n_per_subject=min_num_sessions)\n",
    "print(f'The minimum number of sessions in both groups is: {min_num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe957951-c0c9-422f-8e90-883041a3bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose randomized sets but an equal number of days apart\n",
    "n_random = 3 \n",
    "n_to_pick = 1\n",
    "rnd = np.random.default_rng(seed = 23)\n",
    "c_mice,h_mice,h_deltadays, c_deltadays, c_sua, c_mua, h_mua, h_sua = [],[],[],[],[],[],[],[]\n",
    "for i,cemented_session in cemented_sessions.iterrows():\n",
    "    cem_delta_days = (cemented_session.session_datetime - cemented_sessions.session_datetime.min()).days\n",
    "    hol_delta_days = np.array([x.days for x in chronic_holder_sessions.session_datetime - chronic_holder_sessions.session_datetime.min()])\n",
    "    sorted_day_distance = np.argsort(np.abs(hol_delta_days-cem_delta_days))\n",
    "    ff = rnd.choice(sorted_day_distance[:n_random],n_to_pick,replace=False)\n",
    "    comparison_sessions = chronic_holder_sessions.iloc[ff]\n",
    "    #print(cemented_session.subject_name, cemented_session.session_name, comparison_sessions.iloc[0].subject_name, comparison_sessions.iloc[0].session_name)\n",
    "    c_sua.append(cemented_session.sua)\n",
    "    c_mua.append(cemented_session.mua)\n",
    "    deltadays = cemented_session.session_datetime - cemented_sessions.session_datetime.min()\n",
    "    c_deltadays.append(deltadays.days)\n",
    "    c_mice.append(cemented_session.subject_name)\n",
    "\n",
    "    h_sua.append(comparison_sessions.sua.mean())\n",
    "    h_mua.append(comparison_sessions.mua.mean())\n",
    "    deltadays = comparison_sessions.session_datetime - chronic_holder_sessions.session_datetime.min()\n",
    "    h_deltadays.append(deltadays.iloc[0].days)\n",
    "    h_mice.append(comparison_sessions.iloc[0].subject_name)\n",
    "# plot the number of units for several session from the cemented probes and the chronic holder\n",
    "\n",
    "_, h_cols = np.unique(h_mice, return_inverse=True)\n",
    "_, c_cols = np.unique(c_mice, return_inverse=True)\n",
    "\n",
    "labels = ['Cemented','Chronic holder'] * 2\n",
    "leg_labels = []\n",
    "xticks = (1,2,3.5,4.5)\n",
    "scatter_pos = []\n",
    "fig = plt.figure(figsize = [3,3])\n",
    "\n",
    "for i,(pos,n_units) in enumerate(zip(xticks,[c_mua, h_mua, c_sua, h_sua])):\n",
    "    scatter_positions = rnd.normal(0, scale=.05, size=len(n_units))\n",
    "    scatter_pos.append(scatter_positions+pos)\n",
    "    if i % 2 == 0:\n",
    "        plt.scatter(pos+scatter_positions, n_units, s=25, c=c_deltadays, alpha=.7, cmap='plasma',edgecolors = 'none')\n",
    "    else:\n",
    "        plt.scatter(pos+scatter_positions, n_units, s=25, c=h_deltadays, alpha=.7, cmap='plasma',edgecolors = 'none')\n",
    "\n",
    "    plt.hlines(np.median(n_units), pos-.3, pos+.3, color='black')\n",
    "\n",
    "nsess = len(c_mua)\n",
    "plt.plot(np.stack(scatter_pos[:2]), np.stack([c_mua, h_mua], axis=1).T, \n",
    "         linewidth=.5, color='black', alpha=.5)\n",
    "plt.plot(np.stack(scatter_pos[2:]), np.stack([c_sua, h_sua], axis=1).T, \n",
    "         linewidth=.5, color='black', alpha=.5)\n",
    "# plt.plot(np.repeat(np.expand_dims(xticks[2:],1),nsess, axis=1), np.stack([c_sua, h_sua], axis=1).T, \n",
    "#          linewidth=.5, color='black', alpha=.5)\n",
    "\n",
    "plt.colorbar(label='days from first recording',shrink = 0.2)\n",
    "\n",
    "plt.xticks(xticks, labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks([0,300,600])\n",
    "plt.ylabel('Unit yield')\n",
    "plt.xlabel('')\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "plt.savefig(SAVEPATH / 'cemented_comparison_unit_yield.pdf', bbox_inches='tight', dpi=300, format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c1c6e-6ec8-48cd-b097-9af079b5be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "ks_2samp(c_sua,h_sua),np.mean(c_sua),np.std(c_sua)/np.sqrt(len(h_sua)),np.mean(h_sua),np.std(h_sua)/np.sqrt(len(h_sua))\n",
    "# ks_2samp(c_mua,h_mua),np.median(c_mua),np.median(h_mua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units yield over time\n",
    "# plt.figure(figsize = (3,3))\n",
    "plt.figure(figsize = (10,2))\n",
    "markers = ['.','s','^','d','<','D','>','p','>','h','H','.','s','^','d','|','_']\n",
    "c = 0\n",
    "# subjects = ['JC131', 'MM008', '_AL031', '_AL036']\n",
    "subjects = ['JC131', 'JC162','JC142','MM018','MM013','_AL031', '_AL036','_AL032']\n",
    "probes = [0,2,2,0,0,0]\n",
    "parameter_set_num = 5\n",
    "unit_criteria_id = 1\n",
    "color = '#d62728'\n",
    "for i,s in enumerate(subjects):\n",
    "    probenums = (EphysRecording.ProbeSetting & dict(subject_name=s, parameter_set_num=5)).fetch('probe_num')\n",
    "    n_probes = np.unique(probenums)\n",
    "    for p in n_probes:\n",
    "        config_ids = (Session * EphysRecording.ProbeSetting * UnitCount & dict(subject_name=s, probe_num=p, \n",
    "                                                                               parameter_set_num=parameter_set_num,\n",
    "                                                                               unit_criteria_id=unit_criteria_id)).fetch('configuration_id')\n",
    "        ids, counts = np.unique(config_ids, return_counts=True)\n",
    "        config_id = ids[np.argmax(counts)]\n",
    "        print(f'Using configuration ID {config_id} for subject {s}, probe {p}')\n",
    "        query = EphysRecording.ProbeSetting * Session * UnitCount & dict(probe_num=p, subject_name=s, \n",
    "                                                                         configuration_id=config_id, \n",
    "                                                                         unit_criteria_id=unit_criteria_id,\n",
    "                                                                         parameter_set_num=parameter_set_num)\n",
    "        # find the indices for the closest sessions to the target days\n",
    "        datetimes, nsua = query.fetch('session_datetime','sua')\n",
    "        delta_days = (datetimes - datetimes[0]).astype('timedelta64[D]').astype(int)\n",
    "        target_delta = 10\n",
    "        targeted_days = np.arange(np.random.uniform(0,target_delta/2), np.max(delta_days)+target_delta+1, target_delta).astype(int)\n",
    "        session_inds_to_use = np.unique([np.absolute(delta_days-target_day).argmin() for target_day in targeted_days])\n",
    "\n",
    "        label = f'{s.replace(\"_\",\"\")} probe {p}'\n",
    "        #plt.plot(delta_days[session_inds_to_use], nsua[session_inds_to_use], color='black', alpha=0.5, linewidth=1)\n",
    "        if '_' in s:\n",
    "            plt.scatter(delta_days[session_inds_to_use], nsua[session_inds_to_use], s=10, color='black',facecolors = 'none', marker=markers[c], label=label,alpha = 1)\n",
    "            plt.plot(delta_days[session_inds_to_use], nsua[session_inds_to_use], color='black', alpha=0.7, linewidth=1)\n",
    "        else:\n",
    "            plt.scatter(delta_days[session_inds_to_use], nsua[session_inds_to_use], s=10,  color=color, facecolors = 'none', marker=markers[c], label=label,alpha = 1)\n",
    "            plt.plot(delta_days[session_inds_to_use], nsua[session_inds_to_use], color=color, alpha=0.7, linewidth=1)\n",
    "            \n",
    "        c+=1\n",
    "    \n",
    "plt.ylim(0,400)\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "plt.xlabel('Days from first recording')\n",
    "plt.ylabel('N single units')\n",
    "# plt.legend()\n",
    "plt.yticks([0,150,300])\n",
    "plt.xticks([0,60,120,180,240,300])\n",
    "# plt.savefig(savepath/f'subsampled_unit_counts_over_time.pdf')\n",
    "plt.ylabel('# simultaneously\\n recorded single units\\n(log)');\n",
    "plt.savefig(savepath/f'subsampled_unit_counts_over_time_stretched.pdf')\n",
    "\n",
    "plt.ylim([10,1000])\n",
    "plt.gca().set_yscale('log')\n",
    "plt.yticks([5,50,500],[5,50,500])\n",
    "plt.ylabel('# simultaneously\\n recorded single units\\n(log)');\n",
    "plt.savefig(savepath/f'subsampled_unit_counts_over_time_stretched_log.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d2dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
