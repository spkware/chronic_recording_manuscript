{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the drift (estimated with DREDGE) across days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "#matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "from labdata.schema import *\n",
    "\n",
    "SAVEPATH = Path(r'/home/mmelin/chronic_manuscript_figures')\n",
    "T_START_SEC = 300\n",
    "T_END_SEC = 500 # grab spikes from minutes 5 to 10\n",
    "PROBE_NUM = 0\n",
    "SHANK_NUMS = [0, 1, 2, 3]\n",
    "\n",
    "session_offset_sec = T_END_SEC - T_START_SEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for orientation sessions\n",
    "ori_session_keys = (Dataset() & 'subject_name = \"JC131\"' & 'dataset_name LIKE \"%ori%%\"').fetch('session_name', as_dict=True)\n",
    "ori_session_keys = (Dataset() & 'subject_name = \"JC131\"' & 'dataset_name LIKE \"%Droplets%\"').fetch('session_name', as_dict=True)\n",
    "#drop_session_keys = (Dataset() & 'subject_name = \"JC131\"' & 'dataset_name LIKE \"%Droplet%%\"').fetch('session_name', as_dict=True)\n",
    "\n",
    "# query for sessions with the proper probe configuration and sorting parameters (no motion correction applied)\n",
    "query1 = SpikeSorting * Session * EphysRecording.ProbeSetting() \\\n",
    "    & ori_session_keys \\\n",
    "    & 'parameter_set_num = 8' \\\n",
    "    & 'configuration_id = 3' \\\n",
    "    #& f'session_datetime < \"2023-11-8\"' \n",
    "    #& 'session_name <> \"20231025_183538\"' # exclude broken recording\n",
    "\n",
    "session_dates = query1.fetch('session_name', order_by='session_datetime')\n",
    "\n",
    "query = UnitMetrics * SpikeSorting.Unit * Session * EphysRecording.ProbeSetting() \\\n",
    "    & ori_session_keys \\\n",
    "    & 'parameter_set_num = 8' \\\n",
    "    & 'configuration_id = 3' \\\n",
    "    #& f'session_datetime < \"2023-11-8\"' \\\n",
    "    #& f'shank = {SHANK_NUM}'\n",
    "\n",
    "query & f'session_name = \"{session_dates[0]}\"' \n",
    "\n",
    "#session_date = session_dates[0:3] # just for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spike_data(session_dates, query, shank_num, t_start_sec, t_end_sec):\n",
    "    #session_dates = session_dates[0:10] # testing\n",
    "    session_offset_sec = t_end_sec - t_start_sec\n",
    "    all_spikes = []\n",
    "    spks = {}\n",
    "    session_breaks = []\n",
    "    for o,d in enumerate(tqdm(session_dates)):\n",
    "        k = (query & dict(session_name=d, shank=shank_num)).proj()\n",
    "        dat = (query & k).fetch('spike_amplitudes','spike_times','spike_positions', as_dict=True)\n",
    "        fs = (EphysRecording.ProbeSetting() & f'session_name = \"{d}\"' & f'probe_num = {PROBE_NUM}').fetch1('sampling_rate')\n",
    "        for i in range(len(dat)): # loop over units\n",
    "            #plt.hist(dat[i]['spike_positions'][:,0]) # plot for spike positions\n",
    "            timeinds2grab = np.logical_and(dat[i]['spike_times'] > t_start_sec * fs, dat[i]['spike_times'] < t_end_sec * fs)\n",
    "            #shankinds2grab = np.logical_and(dat[i]['spike_positions'][:,0] > 0, dat[i]['spike_positions'][:,0] < 150) #FIXME: this is a temp fix until waveform positions are fixed\n",
    "            #shankinds2grab = np.logical_and(dat[i]['spike_positions'][:,0] > 500, dat[i]['spike_positions'][:,0] < 650) #FIXME: this is a temp fix until waveform positions are fixed\n",
    "            if shank_num in (0,1):\n",
    "                depthinds2grab = dat[i]['spike_positions'][:,1] < 4790\n",
    "            elif shank_num in (2,3):\n",
    "                depthinds2grab = dat[i]['spike_positions'][:,1] < 3500\n",
    "            #inds2grab = np.logical_and.reduce([timeinds2grab, shankinds2grab, depthinds2grab])\n",
    "            inds2grab = np.logical_and(timeinds2grab, depthinds2grab)\n",
    "            if np.sum(inds2grab) == 0:\n",
    "                continue\n",
    "            #spks = {}\n",
    "            spks['amps'] =  dat[i]['spike_amplitudes'][inds2grab]\n",
    "            spks['depths_um'] = dat[i]['spike_positions'][inds2grab,1]\n",
    "            spike_times_s = dat[i]['spike_times'][inds2grab] / fs\n",
    "            spks['times_s'] = spike_times_s + session_offset_sec*o - t_start_sec\n",
    "            all_spikes.append(spks)\n",
    "        session_breaks.append(session_offset_sec*o)\n",
    "\n",
    "    all_spikes = pd.DataFrame(all_spikes).apply(lambda col: col.explode())\n",
    "    session_breaks = np.array(session_breaks[1:])\n",
    "    return all_spikes, session_breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shank_spikes = []\n",
    "for s in SHANK_NUMS:\n",
    "    all_spikes_on_shank, session_breaks = get_spike_data(session_dates, query, s, T_START_SEC, T_END_SEC)\n",
    "    shank_spikes.append(all_spikes_on_shank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shank_spikes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "savepath = Path(r'/home/mmelin/data/JC131combinedspikes')\n",
    "for i,spks in enumerate(shank_spikes):\n",
    "    spks.to_csv(savepath / f'shank_{i}_spikes.csv')\n",
    "\n",
    "np.save(savepath / f'session_breaks.npy', session_breaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/joao/lib/dredge/dredge-python/')\n",
    "from dredge.dredge_ap import register\n",
    "\n",
    "shank_motion_estimates = []\n",
    "for all_spikes_on_shank in shank_spikes:\n",
    "    motion_est, _ = register(**all_spikes_on_shank, bin_s=1)\n",
    "    shank_motion_estimates.append(motion_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spks.viz import plot_drift_raster\n",
    "\n",
    "for i,shank in enumerate(SHANK_NUMS):\n",
    "    all_spikes = shank_spikes[i]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plot_drift_raster(all_spikes['times_s'], all_spikes['depths_um'], all_spikes['amps'], n_spikes_to_plot=50_000, rasterized=True, cmap='gray_r',clim=(0,100))\n",
    "    plt.vlines(session_breaks, *plt.gca().get_ylim(), linewidth=.5, linestyles='--', colors='black', label='Session breaks')\n",
    "\n",
    "    motion_est = shank_motion_estimates[i]\n",
    "    offset = np.mean(plt.ylim())\n",
    "    plt.plot(motion_est.time_bin_centers_s, offset + motion_est.displacement.T, color='red', lw=1, alpha=.8)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Depth along shank (um)')\n",
    "    plt.legend()\n",
    "    #plt.savefig(SAVEPATH / f'JC131_across_session_drift_shank_{shank}.pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = np.concatenate([np.array([0]), session_breaks])\n",
    "\n",
    "def compute_intersession_drift(motion_est, lims):\n",
    "    avg_pos = []\n",
    "    for start, end in zip(lims[:-1], lims[1:]):\n",
    "        avg_pos.append(np.mean(motion_est.displacement[start:end])) # mean position per session\n",
    "    diffs = np.diff(avg_pos)\n",
    "    return avg_pos, diffs\n",
    "\n",
    "#intersession_positions, intersession_drifts = [(compute_intersession_drift(m, lims)) for m in shank_motion_estimates]\n",
    "intersession_drifts = [compute_intersession_drift(m, lims) for m in shank_motion_estimates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos,delta in intersession_drifts:\n",
    "    fig, ax = plt.subplots(figsize=(12,2))\n",
    "    plt.plot(np.arange(len(pos)),pos, color='black', linewidth=.8, alpha=.4)\n",
    "    plt.scatter(np.arange(len(pos)),pos, color='red')\n",
    "    plt.ylim(-50,50)\n",
    "    plt.xlabel('Days from first session')\n",
    "    plt.ylabel('Shank position (um)')\n",
    "    plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "    plt.savefig(SAVEPATH / f'JC131_shank_pos_shank_{shank}.pdf', bbox_inches='tight', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,2))\n",
    "cols = ['black','red','red','red']\n",
    "marker = ['o','o','o','o']\n",
    "drifts_2_plot = [intersession_drifts[0], intersession_drifts[2]]\n",
    "for i,(pos,delta) in enumerate(drifts_2_plot):\n",
    "    plt.plot(np.arange(len(pos)),pos, color='black', linewidth=.8, alpha=.4)\n",
    "    plt.scatter(np.arange(len(pos)),pos, color=cols[i], marker=marker[i], s=18)\n",
    "\n",
    "plt.ylim(-50,50)\n",
    "plt.xlabel('Days from first session')\n",
    "plt.ylabel('Shank position (um)')\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "plt.savefig(SAVEPATH / f'JC131_shank_pos_all_shanks.pdf', bbox_inches='tight', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = []\n",
    "x = 0\n",
    "cols = ['black','black','red','red']\n",
    "cols = ['grey','grey','red','red']\n",
    "labs = ['Shank 0','Shank 1','Shank 2','Shank 3']\n",
    "for i,(pos,delta) in enumerate(intersession_drifts):\n",
    "    scatter_positions = np.random.normal(x, .03, len(delta))\n",
    "    #fig, ax = plt.subplots(figsize=(2,4))\n",
    "    parts = plt.violinplot([delta], [x], showextrema=False, showmedians=False)\n",
    "    plt.scatter(scatter_positions, delta, color='black', s=4, alpha=.5)\n",
    "    quartile1, median, quartile3 = np.percentile(delta, [25, 50, 75])\n",
    "    plt.hlines(median, x - .1, x + .1, color='black', linestyle='-', lw=2)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(cols[i])\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(1)\n",
    "    xvals.append(x)\n",
    "    x += .6\n",
    "\n",
    "plt.ylim(-40, 40)\n",
    "plt.ylabel('Drift between sessions (um)')\n",
    "plt.xlabel('')\n",
    "plt.xticks(xvals, labs)\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "#plt.savefig(SAVEPATH / f'JC131_drift_violin_shank_{i}.pdf', bbox_inches='tight', dpi=500)\n",
    "plt.savefig(SAVEPATH / f'JC131_drift_violin_all_shanks.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_spikes['depths_um'])\n",
    "plt.xlabel('depth (from kilosort)')\n",
    "plt.show()\n",
    "plt.hist((query & 'shank = 0').fetch('depth'))\n",
    "plt.xlabel('depth (from avg waveform)')\n",
    "plt.show()\n",
    "plt.plot(all_spikes['times_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = (ProbeConfiguration() & 'configuration_id = 3' & 'probe_id = 20403312753').fetch('channel_coords')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*xy.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
