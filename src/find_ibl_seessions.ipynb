{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.api import ONE\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import vvasp\n",
    "from iblatlas.regions import BrainRegions\n",
    "from iblatlas.atlas import AllenAtlas, Insertion\n",
    "from labdata.schema import *\n",
    "from labdata import chronic_paper as cp\n",
    "\n",
    "one = ONE()\n",
    "br = BrainRegions()\n",
    "ba = AllenAtlas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pids = one.search_insertions(atlas_acronym=['CP'])\n",
    "subjects = np.unique(cp.ChronicInsertion().fetch('subject_name', order_by='procedure_datetime')).tolist()\n",
    "#Subject()\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbeInsertion() * Probe() & dict(subject_name='MM013')\n",
    "(ProbeInsertion() * Probe() & 'probe_n_shanks=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = pv.Plotter()\n",
    "atlas = vvasp.VVASPAtlas(plotter)\n",
    "\n",
    "sub = 'MM013'\n",
    "\n",
    "insertions = (ProbeInsertion() * Probe() & dict(subject_name=sub)).fetch(as_dict=True)\n",
    "ikey = (ProbeInsertion() * Probe() & dict(subject_name=sub)).fetch('KEY', as_dict=True)\n",
    "print(f'\\n\\nThere are {len(insertions)} insertions for {sub}')\n",
    "prbs = []\n",
    "for ins in insertions:\n",
    "#for ins in [insertions[0]]:\n",
    "    angles = np.array([ins['insertion_el'], ins['insertion_spin'], ins['insertion_az']])\n",
    "    entry = np.array([ins['insertion_ml'], ins['insertion_ap']])\n",
    "    depth = ins['insertion_depth']\n",
    "    # TODO: get probetype first \n",
    "    if ins['probe_n_shanks'] == 1:\n",
    "        prb = vvasp.Probe('NP1', plotter)\n",
    "    elif ins['probe_n_shanks'] == 4:\n",
    "        prb = vvasp.Probe('NP24', plotter)\n",
    "    else:\n",
    "        raise ValueError('Probe type not supported')\n",
    "    prb.drive_probe_from_entry(entry, angles, ins['insertion_depth'], root_mesh=atlas.meshes['root']) # position the probe via an entry point, angles and driven depth\n",
    "    _, region_acronyms = prb.compute_region_intersections(atlas)\n",
    "    prbs.append(prb)\n",
    "    region_acronyms = np.unique([item for sublist in region_acronyms for item in sublist])\n",
    "    region_acronyms = np.unique(br.acronym2acronym(region_acronyms, mapping='Beryl'))\n",
    "    region_acronyms = [x for x in region_acronyms if x != 'Outside atlas']\n",
    "    region_acronyms = [x for x in region_acronyms if x[0].isupper()]\n",
    "    _ = [atlas.add_atlas_region_mesh(r) for r in region_acronyms]\n",
    "    print(region_acronyms)\n",
    "    pids = [one.search_insertions(atlas_acronym=ra, project='brainwide') for ra in region_acronyms]\n",
    "    pids = np.unique(np.concatenate(pids, axis=0))\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = '57656bee-e32e-4848-b924-0f6f18cfdfb1'\n",
    "traj = one.alyx.rest('trajectories', 'list', probe_insertion=pid,\n",
    "                         provenance='Ephys aligned histology track')\n",
    "assert len(traj) == 1\n",
    "traj = traj[0]\n",
    "ins = Insertion.from_dict(traj, brain_atlas=ba)\n",
    "prb = vvasp.Probe('NP1', plotter)\n",
    "tip = ins.tip * 1e6\n",
    "entry = np.array([traj['x'], traj['y']])\n",
    "angles = np.array([90 + traj['theta'], traj['roll'], traj['phi'] - 90 + 180])\n",
    "angles = np.array([90 - traj['theta'], traj['roll'], traj['phi'] - 90])\n",
    "#angles = np.array([traj['theta'] - 90, traj['roll'], traj['phi']])\n",
    "prb.set_location(tip, angles)\n",
    "#prb.drive_probe_from_entry(entry, angles, traj['depth'], root_mesh=atlas.meshes['root']) # position the probe via an entry point, angles and driven depth\n",
    "prb.make_inactive()\n",
    "\n",
    "_, region_acronyms = prb.compute_region_intersections(atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = dict(**ikey[2],\n",
    "             pid ='57acb640-4f64-4a89-bedf-69351a3aea75',)\n",
    "#cp.IBLMatchedInsertion().insert1(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.IBLMatchedInsertion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_insertions = cp.IBLMatchedInsertion().fetch(as_dict=True)\n",
    "for m in matched_insertions:\n",
    "    pid = m.pop('pid')\n",
    "    eid, probename = one.pid2eid(pid)\n",
    "    session_dict = one.eid2ref(eid)\n",
    "\n",
    "    # 1. insert the subject if it's not there\n",
    "    alyx_sub = one.alyx.rest('subjects', 'read', id=session_dict['subject'])\n",
    "    subj_dict = dict(subject_name=f'_{session_dict[\"subject\"]}',\n",
    "                     subject_dob=alyx_sub['birth_date'],\n",
    "                     subject_sex=alyx_sub['sex'],\n",
    "                     user_name='mmelin',\n",
    "                     strain_name='C57BL/6J')\n",
    "    print(subj_dict)\n",
    "    Subject().insert1(subj_dict, skip_duplicates=True)\n",
    "\n",
    "    # 2. Download the session data\n",
    "    bin_dset = one.list_datasets(eid, '*.ap.cbin', collection=f'raw_ephys_data/{probename}')\n",
    "    meta_dset = one.list_datasets(eid, '*.ap.meta', collection=f'raw_ephys_data/{probename}')\n",
    "    assert len(bin_dset) == 1\n",
    "    assert len(meta_dset) == 1\n",
    "    bin_dset = bin_dset[0]\n",
    "    meta_dset = meta_dset[0]\n",
    "\n",
    "    bin_path = one.load_dataset(eid, bin_dset, download_only=True)\n",
    "    meta_path = one.load_dataset(eid, meta_dset, download_only=True)\n",
    "\n",
    "    # 3. insert the ephys session\n",
    "\n",
    "    \n",
    "    # 4. clean up (delete the local files that were downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = one.alyx.rest('subjects', 'read', id='MM012')\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
